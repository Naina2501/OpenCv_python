{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49fc36af-aeae-40e0-9c1b-70b9de96e5dc",
   "metadata": {},
   "source": [
    "# WORK ON OPENCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a888aa-3f9e-46e1-9978-eebf73a084f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27e5d504-8367-4f49-9e50-8b68a50990f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"one.jpg\") #imageread\n",
    "cv2.imshow(\"wallpaper\",img) #show image (\"name\",var)\n",
    "cv2.waitKey(0) #stop image frame wait for 1 ms and 0 pass keyboard any key press\n",
    "cv2.destroyAllWindows()  #all window close\n",
    "#cv2.destroyWindow()      #only one window close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "741af3bc-a9ed-4568-b83d-81542c737ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img=cv2.imread(\"one.jpg\") #imageread\n",
    "cv2.imshow(\"wallpaper\",img) #show image (\"name\",var)\n",
    "cv2.imshow(\"wallpaper2\",img) #show image (\"name\",var)\n",
    "cv2.waitKey(0) #stop image frame wait for 1 ms and 0 pass keyboard any key press\n",
    "cv2.destroyAllWindows()  #all window close\n",
    "#cv2.destroyWindow(\"wallpaper\")      #only one window close\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e202e6b-ebea-44d5-bb71-976800a9c081",
   "metadata": {},
   "source": [
    "show multiple image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50419c4e-82f7-4cb7-8df2-afec8587eed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"five.jpg\")\n",
    "resize_image=cv2.resize(img,(400,300))\n",
    "cv2.imshow(\"five\",resize_image) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c6e8af8-b386-4b80-9f06-23cec536fa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[12  0  0]\n",
      "  [12  0  0]\n",
      "  [12  0  0]\n",
      "  ...\n",
      "  [ 2  0  0]\n",
      "  [ 6  0  5]\n",
      "  [ 4  0  4]]\n",
      "\n",
      " [[19  3  0]\n",
      "  [19  4  0]\n",
      "  [19  3  0]\n",
      "  ...\n",
      "  [ 4  1 10]\n",
      "  [10  4 15]\n",
      "  [ 8  1 14]]\n",
      "\n",
      " [[49 30 17]\n",
      "  [49 30 15]\n",
      "  [49 30 17]\n",
      "  ...\n",
      "  [26 23 45]\n",
      "  [35 29 54]\n",
      "  [37 28 55]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[16 21 20]\n",
      "  [17 22 21]\n",
      "  [17 22 21]\n",
      "  ...\n",
      "  [34 26 37]\n",
      "  [33 25 36]\n",
      "  [32 24 35]]\n",
      "\n",
      " [[18 23 22]\n",
      "  [18 23 22]\n",
      "  [18 23 22]\n",
      "  ...\n",
      "  [34 26 37]\n",
      "  [33 25 36]\n",
      "  [32 24 35]]\n",
      "\n",
      " [[19 24 23]\n",
      "  [19 24 23]\n",
      "  [20 25 24]\n",
      "  ...\n",
      "  [34 26 37]\n",
      "  [33 25 36]\n",
      "  [32 24 35]]]\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread(\"five.jpg\")\n",
    "print(img) #rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6274ec4a-1e7e-489b-8c23-c00965230fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"five.jpg\")\n",
    "resize_image=cv2.resize(img,(300,300))\n",
    "h=np.hstack((resize_image,resize_image,resize_image)) #horizontal stack of array\n",
    "v=np.vstack((h,h))\n",
    "cv2.imshow(\"five\",v) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd3c939-c0d3-4fc1-96de-b340bb263b03",
   "metadata": {},
   "source": [
    "#SLIDE SHOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dde0d01-4e80-4521-a53f-1523dffac24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['five.jpg', 'four.jpg', 'one.jpg', 'three.jpg', 'two.jpg']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_img=os.listdir(r\"C:\\Users\\Hp\\Documents\\Python learning\\opencv\\project_image\")\n",
    "list_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8829774a-4e38-409a-a6fc-8625da2d08c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in list_img:\n",
    "    path=\"C:\\\\Users\\\\Hp\\\\Documents\\\\Python learning\\\\opencv\\\\project_image\"\n",
    "    img_name=path + \"\\\\\" + name\n",
    "    img=cv2.imread(img_name)\n",
    "    img=cv2.resize(img,(400,600))\n",
    "    cv2.imshow(\"hello\",img) \n",
    "    cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8f7c1d8-1bc8-4575-b42d-adc49a9139dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread(\"project_image/three.jpg\")\n",
    "img=cv2.resize(img,(500,500))\n",
    "cv2.imshow(\"hello\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846c4c87-fa76-413c-861a-251f6adc8598",
   "metadata": {},
   "source": [
    "TEXT PROPERTY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7de904f-4341-4c95-bdb6-3370be603199",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "org : (X coordinate value, Y coordinate value)\n",
    "fontFace :\n",
    ". FONT_HERSHEY_SIMPLEX = 0\n",
    ". FONT_HERSHEY_PLAIN = 1\n",
    ". FONT_HERSHEY_DUPLEX = 2\n",
    ". FONT_HERSHEY_COMPLEX = 3\n",
    ". FONT_HERSHEY_TRIPLEX = 4\n",
    ". FONT_HERSHEY_COMPLEX_SMALL = 5\n",
    ". FONT_HERSHEY_SCRIPT_SIMPLEX = 6\n",
    ". FONT_HERSHEY_SCRIPT_COMPLEX = 7\n",
    "\n",
    "color : BGR. (255, 0,0)\n",
    "\n",
    "line Type :\n",
    ". FILLED =- 1\n",
    ". LINE_4 = 4\n",
    ". LINE_8 = 8\n",
    ". LINE_AA = 16\n",
    "\n",
    "bottomLeftOrigin : This is an optional parameter. When it is true,manage data\n",
    "origin is at the bottom-left corner. Otherwise, it is at the top-left corner\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ffe8f28-ec84-4775-8a51-075b36431dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img_get=cv2.imread(\"project_image/three.jpg\")\n",
    "print(img.shape)\n",
    "img_get=cv2.resize(img_get,(500,500))\n",
    "\n",
    "txt=cv2.putText(img=img_get,\n",
    "    text=\"hello to new world of programing\",\n",
    "    org=(50,80),\n",
    "    fontFace=cv2.FONT_HERSHEY_DUPLEX,\n",
    "    fontScale=3,\n",
    "    color=(0,0,255),\n",
    "    thickness=3,\n",
    "    lineType=cv2.LINE_8,\n",
    "    bottomLeftOrigin=False)\n",
    "txt=cv2.putText(img=img_get,\n",
    "    text=\"hello to new world of programing\",\n",
    "    org=(50,80),\n",
    "    fontFace=cv2.FONT_HERSHEY_DUPLEX,\n",
    "    fontScale=3,\n",
    "    color=(0,255,0),\n",
    "    thickness=3,\n",
    "    lineType=cv2.LINE_8,\n",
    "    bottomLeftOrigin=True)\n",
    "cv2.imshow(\"hello\",txt)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d428e9-5e5a-4797-9474-82f87cc5430d",
   "metadata": {},
   "source": [
    "#drawline on image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1641f797-bfb7-4928-97cb-2f40949d9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "old_img=cv2.imread(\"project_image/three.jpg\")\n",
    "old_img =cv2.resize(old_img,(600,500))\n",
    "\n",
    "#new_img = cv2.line(img = old_img, pt1 =(290,140),  pt2=(440,140), color =(0,0,255), thickness=4, lineType = 16)\n",
    "txt=cv2.putText(img=old_img,text=\"hello\",org=(100,90), fontFace=cv2.FONT_HERSHEY_DUPLEX,\n",
    "    fontScale=3,color=(0,255,0),thickness=2,lineType=cv2.LINE_8,bottomLeftOrigin=False)\n",
    "new_img=cv2.rectangle(img=txt,pt1=(270,140),pt2=(430,330),color=(0,255,0),thickness=4, lineType = 8)\n",
    "\n",
    "cv2.imshow(\"hello\",new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fff7f3-e8fb-4a08-a4c0-15f38c27a3aa",
   "metadata": {},
   "source": [
    "\n",
    "#draw circle on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fb5f7cd-4f14-4312-b1f1-3f609423fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "old_img=cv2.imread(\"project_image/three.jpg\")\n",
    "old_img =cv2.resize(old_img,(600,500))\n",
    "\n",
    "#cir_img=cv2.circle(img = old_img,center=(350,210),radius=120, color =(0,255,0), thickness=1, lineType = 16)\n",
    "ellipse_img=cv2.ellipse(img = old_img,center=(350,210),axes=(90,150),angle=45,startAngle=0,endAngle=360,color =(0,255,0), thickness=2, lineType = 16)\n",
    "\n",
    "cv2.imshow(\"hello\",old_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e15ba52-56a4-45f5-a785-e854562f20fc",
   "metadata": {},
   "source": [
    "Draw polygons on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91cf8dd9-9b09-4050-b5f1-32260673f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "old_img=cv2.imread(\"project_image/two.jpg\")\n",
    "old_img =cv2.resize(old_img,(600,500))\n",
    "\n",
    "poly_img=cv2.polylines(img=old_img,pts=[np.array([[100,200],[150,200],[300,400],[300,500],[100,500]])],isClosed=True,color =(0,255,0), thickness=4, lineType = 16)\n",
    "\n",
    "cv2.imshow(\"hello\",old_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64af1021-62ed-4507-a76d-1014a6b0c211",
   "metadata": {},
   "source": [
    "Arithmatic operation on images on screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f9954a6-4db6-41fe-a230-4d1a3f7cb0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_img=cv2.imread(\"project_image/two.jpg\")\n",
    "two_img=cv2.imread(\"project_image/one.jpg\")\n",
    "one_img =cv2.resize(one_img,(500,500))\n",
    "two_img =cv2.resize(two_img,(500,500))\n",
    "\n",
    "#new_img=cv2.addWeighted(one_img,1, two_img, 1,1) #dst @brief Calculates the weighted sum of two arrays.merging the image\n",
    "new_img=cv2.subtract(two_img,one_img)\n",
    "cv2.imshow(\"hello\",new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a996ea6-0c52-4fa5-9bfc-c19800615ecd",
   "metadata": {},
   "source": [
    "#BITWISE OPERATION\n",
    "and\n",
    "or \n",
    "not\n",
    "Exor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e1a7876-5192-49cd-a423-1b4d7f18813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_img=cv2.imread(\"project_image/three.jpg\")\n",
    "two_img=cv2.imread(\"project_image/four.jpg\")\n",
    "one_img =cv2.resize(one_img,(500,500))\n",
    "two_img =cv2.resize(two_img,(500,500))\n",
    "\n",
    "#new_img=cv2.bitwise_and(two_img,one_img)\n",
    "#new_img=cv2.bitwise_or(two_img,one_img)\n",
    "#new_img=cv2.bitwise_xor(two_img,one_img)\n",
    "new_img=cv2.bitwise_not(one_img)\n",
    "h1=np.hstack((one_img,two_img,new_img))\n",
    "\n",
    "cv2.imshow(\"hello\",h1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296f6def-c429-4640-ab93-68eb3221cf3f",
   "metadata": {},
   "source": [
    "#edge detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "519aa337-a207-49d5-a152-9e8a9d3376a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_img=cv2.imread(\"project_image/two.jpg\")\n",
    "one_img =cv2.resize(one_img,(500,500))\n",
    "\n",
    "new_img=cv2.Canny(one_img, 150,90,apertureSize=3,L2gradient=True) #edges @brief Finds edges in an image using the Canny algorithm @cite Canny86 .\n",
    "cv2.imshow(\"hello\",new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6131a3-33d8-4466-b9f5-f21eca18e33c",
   "metadata": {},
   "source": [
    "#image scaling ,Rotating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbf96c3f-bf30-40dd-8d49-48ee9d89107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "one_img=cv2.imread(\"project_image/two.jpg\")\n",
    "res_img =cv2.resize(one_img,(500,500))\n",
    "w,h=res_img.shape[0],res_img.shape[1]\n",
    "\n",
    "r=cv2.getRotationMatrix2D((w/2,h/2),120,1)\n",
    "new=cv2.warpAffine(res_img,r,(w,h))\n",
    "new\n",
    "\n",
    "cv2.imshow(\"hello\",new)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd0a58-14fc-4b37-a47b-f8fb9e33ac81",
   "metadata": {},
   "source": [
    "blurring image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571fc17-9742-4304-91cb-3bdb0f9c0b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_img=cv2.imread(\"project_image/two.jpg\")\n",
    "res_img =cv2.resize(one_img,(500,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "713d6a3c-ea27-4add-8015-1ebb311d0a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function GaussianBlur:\n",
      "\n",
      "GaussianBlur(...)\n",
      "    GaussianBlur(src, ksize, sigmaX[, dst[, sigmaY[, borderType[, hint]]]]) -> dst\n",
      "    .   @brief Blurs an image using a Gaussian filter.\n",
      "    .\n",
      "    .   The function convolves the source image with the specified Gaussian kernel. In-place filtering is\n",
      "    .   supported.\n",
      "    .\n",
      "    .   @param src input image; the image can have any number of channels, which are processed\n",
      "    .   independently, but the depth should be CV_8U, CV_16U, CV_16S, CV_32F or CV_64F.\n",
      "    .   @param dst output image of the same size and type as src.\n",
      "    .   @param ksize Gaussian kernel size. ksize.width and ksize.height can differ but they both must be\n",
      "    .   positive and odd. Or, they can be zero's and then they are computed from sigma.\n",
      "    .   @param sigmaX Gaussian kernel standard deviation in X direction.\n",
      "    .   @param sigmaY Gaussian kernel standard deviation in Y direction; if sigmaY is zero, it is set to be\n",
      "    .   equal to sigmaX, if both sigmas are zeros, they are computed from ksize.width and ksize.height,\n",
      "    .   respectively (see #getGaussianKernel for details); to fully control the result regardless of\n",
      "    .   possible future modifications of all this semantics, it is recommended to specify all of ksize,\n",
      "    .   sigmaX, and sigmaY.\n",
      "    .   @param borderType pixel extrapolation method, see #BorderTypes. #BORDER_WRAP is not supported.\n",
      "    .   @param hint Implementation modfication flags. See #AlgorithmHint\n",
      "    .\n",
      "    .   @sa  sepFilter2D, filter2D, blur, boxFilter, bilateralFilter, medianBlur\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.GaussianBlur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b175803-fe3b-4198-acaf-9d3a09dc29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_img = cv2.imread(\"project_image/two.jpg\")\n",
    "res_img = cv2.resize(org_img,(500,500))\n",
    "\n",
    "gl= cv2.GaussianBlur(res_img, (5,5),0)\n",
    "\n",
    "h = np.hstack((res_img,gl))\n",
    "cv2.imshow(\"wscube\",h)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dceebf5-32b3-45af-b337-1e366033241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_img = cv2.imread(\"project_image/two.jpg\")\n",
    "res_img = cv2.resize(org_img,(500,500))\n",
    "\n",
    "#gl= cv2.medianBlur(res_img, 3)\n",
    "gl= cv2.bilateralFilter(res_img, 9,100,100)\n",
    "\n",
    "h = np.hstack((res_img,gl))\n",
    "cv2.imshow(\"ello\",h)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ac5268-ad92-4738-aab0-955369ebf249",
   "metadata": {},
   "source": [
    "imwrite method for opencv to save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16faa7e4-464f-4e23-9bea-9e241e49f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"project_image/five.jpg\")\n",
    "re_img = cv2.resize(img,(300,300))\n",
    "\n",
    "h = np.hstack((re_img,re_img))\n",
    "v = np.vstack((h,h))\n",
    "\n",
    "cv2.imwrite(\"new_img.png\",v)\n",
    "cv2.imshow(\"hi\",v)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70cca80-8214-4859-b1c9-f13f36ce9c81",
   "metadata": {},
   "source": [
    "makeborder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80e215f7-4966-46b1-b74a-c8c678c75d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"project_image/five.jpg\")\n",
    "img = cv2.resize(img,(300,300))\n",
    "\n",
    "#img1 = cv2.copyMakeBorder(img, 20,20,20,20, cv2. BORDER_CONSTANT, None, value = 2)\n",
    "#img1 = cv2.resize(img1, (300,300))\n",
    "\n",
    "#img2 = cv2.copyMakeBorder(img,20,20,20,20, cv2.BORDER_DEFAULT, None, value = 2)\n",
    "#img2 = cv2.resize(img1,(300,300))\n",
    "#h = np.hstack((img,img1,img2))\n",
    "#img2 = cv2.copyMakeBorder(img,20,20,20,20, cv2.BORDER_REFLECT)\n",
    "#img2 = cv2.copyMakeBorder(img,20,20,20,20, cv2.BORDER_REFLECT_101)\n",
    "img2 = cv2.copyMakeBorder(img,20,20,20,20, cv2.BORDER_ISOLATED)\n",
    "\n",
    "\n",
    "cv2.imshow(\"hello\",img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb9a44b8-510d-486c-950f-eef57f7eee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#play a video \n",
    "\n",
    "cap=cv2.VideoCapture(r\"C:\\Users\\Hp\\Downloads\\rename.mp4\")\n",
    "while cap.isOpened():\n",
    "    r,frame=cap.read()\n",
    "    if r==True:\n",
    "        frame=cv2.resize(frame,(400,500))\n",
    "        cv2.imshow(\"hello\",frame)\n",
    "        if cv2.waitKey(25) & 0xff==ord(\"p\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8a4d1d-90f6-4f0d-9f10-5009d84fc65a",
   "metadata": {},
   "source": [
    "#Capture Video from\n",
    "Camera using\n",
    "OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbb9e17f-4482-42dd-a1e9-55ce03a02cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    r,frame=cap.read()\n",
    "    if r==True:\n",
    "        frame=cv2.resize(frame,(400,500))\n",
    "        cv2.imshow(\"hello\",frame)\n",
    "        if cv2.waitKey(25) & 0xff==ord(\"p\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d5821a-b087-4186-8e3c-8f796f634a28",
   "metadata": {},
   "source": [
    "Slow and Fast\n",
    "Motion\n",
    "Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a3fd52-02a6-46db-b87c-76b6a7bfdefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(r\"C:\\Users\\Hp\\Downloads\\rename.mp4\")\n",
    "while True:\n",
    "    r,frame=cap.read()\n",
    "    if r==True:\n",
    "        frame=cv2.resize(frame,(400,500))\n",
    "        cv2.imshow(\"hello\",frame)\n",
    "        if cv2.waitKey(40) & 0xff==ord(\"p\"):#waitKey(25) for slow motion\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ded598-0dcc-48c1-a788-ad2dd2c8da55",
   "metadata": {},
   "source": [
    "Morphological\n",
    "operations using\n",
    "OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f0712d8-e039-4d9a-88dc-5ed008d88289",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"project_image/six.jpg\")\n",
    "img=cv2.resize(img,(400,500))\n",
    "\n",
    "m=np.ones((40,40),np.int8)\n",
    "#er=cv2.erode(img,m,iterations=1)\n",
    "#di=cv2.dilate(img,m,iterations=1)\n",
    "\n",
    "#op=cv2.morphologyEx(img,cv2.MORPH_OPEN,m)\n",
    "#g=cv2.morphologyEx(img,cv2.MORPH_GRADIENT,m,iterations=1)\n",
    "#top=cv2.morphologyEx(img,cv2.MORPH_TOPHAT,m,iterations=1)\n",
    "blackhat=cv2.morphologyEx(img,cv2.MORPH_BLACKHAT,m,iterations=1)\n",
    "\n",
    "cv2.imshow(\"hello\",img)\n",
    "cv2.imshow(\"he\",blackhat)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c703cd9-ee56-42e4-8899-cc908d36cbb0",
   "metadata": {},
   "source": [
    "image pramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "979e75b1-19ca-4b52-9f68-dc578b649a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 500, 3)\n",
      "(250, 250, 3)\n",
      "(125, 125, 3)\n",
      "(63, 63, 3)\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread(\"project_image/five.jpg\")\n",
    "img=cv2.resize(img,(500,500))\n",
    "print(img.shape)\n",
    "\n",
    "new=cv2.pyrDown(img)\n",
    "print(new.shape)\n",
    "\n",
    "new1=cv2.pyrDown(new)\n",
    "print(new1.shape)\n",
    "\n",
    "new2=cv2.pyrDown(new1)\n",
    "print(new2.shape)\n",
    "\n",
    "cv2.imshow(\"hebb\",img)\n",
    "cv2.imshow(\"he\",new)\n",
    "cv2.imshow(\"he1\",new1)\n",
    "cv2.imshow(\"he2\",new2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ba5dc38-c373-44fa-a0aa-1ea729d11a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200, 3)\n",
      "(400, 400, 3)\n",
      "(800, 800, 3)\n",
      "(1600, 1600, 3)\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread(\"project_image/five.jpg\")\n",
    "img=cv2.resize(img,(200,200))\n",
    "print(img.shape)\n",
    "\n",
    "new=cv2.pyrUp(img)\n",
    "print(new.shape)\n",
    "\n",
    "new1=cv2.pyrUp(new)\n",
    "print(new1.shape)\n",
    "\n",
    "new2=cv2.pyrUp(new1)\n",
    "print(new2.shape)\n",
    "\n",
    "cv2.imshow(\"hebb\",img)\n",
    "cv2.imshow(\"he\",new)\n",
    "cv2.imshow(\"he1\",new1)\n",
    "cv2.imshow(\"he2\",new2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a7dfe3-0378-4ddc-b3c4-e0412f7042f8",
   "metadata": {},
   "source": [
    "image translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91aa63bb-4c18-4e9f-ad1d-bae1b27414ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"project_image/five.jpg\")\n",
    "\n",
    "img = cv2.resize(img,(500,500))\n",
    "\n",
    "# print(img.shape)\n",
    "\n",
    "m = np.float32([[1,0,100], [0,1,50]])\n",
    "new = cv2.warpAffine(img,m, (100,500))\n",
    "\n",
    "cv2.imshow(\"ws1\",img)\n",
    "cv2.imshow(\"ws2\",m)\n",
    "cv2.imshow(\"gf\",new)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531f486f-d77a-4fd8-b0f3-e03e671e0547",
   "metadata": {},
   "source": [
    "Geometric transformation\n",
    "\n",
    "\n",
    "Background substracttion using cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f72c3884-4788-4c1b-a4a8-042a5ccb2a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(r\"C:\\Users\\Hp\\Downloads\\rename.mp4\")\n",
    "m=cv2.createBackgroundSubtractorMOG2()\n",
    "while True:\n",
    "    r,frame=cap.read()\n",
    "    if r==True:\n",
    "        frame=cv2.resize(frame,(300,400))\n",
    "        sub_vid=m.apply(frame)\n",
    "        cv2.imshow(\"video\",sub_vid)\n",
    "        cv2.imshow(\"heloo\",frame)\n",
    "        if cv2.waitKey(25) & 0xff==ord(\"p\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4849b5c3-d5fa-4615-a428-965c6f1fdc79",
   "metadata": {},
   "source": [
    "Extract image from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c475307-454c-4ad9-82e8-25c84c4f15db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(r\"C:\\Users\\Hp\\Downloads\\rename.mp4\")\n",
    "c=0\n",
    "while True:\n",
    "    r,frame=cap.read()\n",
    "    if r==True:\n",
    "        frame=cv2.resize(frame,(300,400))\n",
    "        filename=\"C://Users//Hp//Documents//Python learning//opencv//project_image//org_img\"+ str(c)+\".png\"\n",
    "        cv2.imwrite(filename,frame)\n",
    "        c=c+1\n",
    "        cv2.imshow(\"heloo\",frame)\n",
    "        if cv2.waitKey(25) & 0xff==ord(\"p\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60ba7a3-0144-47ef-a8c8-43c063ec09e2",
   "metadata": {},
   "source": [
    "cvtColor method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20b4ea4d-8db1-4106-a72a-0000c6a7248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_img = cv2.imread(\"project_image/two.jpg\")\n",
    "res_img = cv2.resize(org_img,(500,500))\n",
    "\n",
    "#new=cv2.cvtColor(res_img,cv2.COLOR_BGR2GRAY) #color to gray\n",
    "#new=cv2.cvtColor(res_img,cv2.COLOR_BGR2HSV) #colr to hsv\n",
    "#new=cv2.cvtColor(res_img,cv2.COLOR_BGR2LUV)\n",
    "new=cv2.cvtColor(res_img,cv2.COLOR_BGR2YCrCb)#155 color variant\n",
    "\n",
    "cv2.imshow(\"hello\",res_img)\n",
    "cv2.imshow(\"hello1\",new)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d27b37-0c3e-4c82-9f9b-4728ca941986",
   "metadata": {},
   "source": [
    "Crop image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed701ac-3b5a-42f7-97ac-7e5145c64017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(736, 736, 3)\n"
     ]
    }
   ],
   "source": [
    "org_img = cv2.imread(\"project_image/two.jpg\")\n",
    "res_img = cv2.resize(org_img,(600,800))\n",
    "\n",
    "print(org_img.shape)\n",
    "#img[y1:y2,x1:x2]\n",
    "crop=org_img[150:500,200:]\n",
    "\n",
    "cv2.imshow(\"hello\",res_img)\n",
    "cv2.imshow(\"crop\",crop)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3e657c-bb0f-46c7-b72b-56f6aed137f0",
   "metadata": {},
   "source": [
    "create blank image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc6383c3-abe2-4fce-a20f-ea679f5e291b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138, 98, 3)\n"
     ]
    }
   ],
   "source": [
    "org_img = cv2.imread(\"project_image/six.jpg\")\n",
    "print(org_img.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6705f8df-47db-4201-beec-4a82b82474f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[227 227 227]\n",
      "  [226 226 226]\n",
      "  [225 225 225]\n",
      "  ...\n",
      "  [224 224 224]\n",
      "  [224 224 224]\n",
      "  [224 224 224]]\n",
      "\n",
      " [[ 97  97  97]\n",
      "  [ 96  96  96]\n",
      "  [ 94  94  94]\n",
      "  ...\n",
      "  [ 94  94  94]\n",
      "  [ 94  94  94]\n",
      "  [ 94  94  94]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]]\n"
     ]
    }
   ],
   "source": [
    "print(org_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fd7178c-a8bf-4a41-9cac-7503dcc7842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = np.ones((500,500,3),np.uint8)*255\n",
    "cv2.imshow(\"gf\",new)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d99ec85c-edb2-497c-a74f-293bf104ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = np.zeros((500,500,3),np.uint8)*255\n",
    "cv2.imshow(\"gf\",new)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba19b2c-73b4-4ba1-9260-828746e5fba6",
   "metadata": {},
   "source": [
    "color picker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc02233-51f5-4711-a8ac-7deb2b138604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello(x):\n",
    "    pass\n",
    "\n",
    "\n",
    "new = np.zeros((500,500,3),np.uint8)*255\n",
    "cv2.namedWindow(\"colour\")\n",
    "\n",
    "cv2.createTrackbar(\"R\",\"colour\",0,255,hello)\n",
    "cv2.createTrackbar(\"G\",\"colour\",0,255,hello)\n",
    "cv2.createTrackbar(\"B\",\"colour\",0,255,hello)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"colour\",new)\n",
    "    if cv2.waitKey(1) & 0xff == ord(\"p\"):\n",
    "        break\n",
    "    r=cv2.getTrackbarPos(\"R\",\"colour\")\n",
    "    g=cv2.getTrackbarPos(\"G\",\"colour\")\n",
    "    b=cv2.getTrackbarPos(\"B\",\"colour\")\n",
    "    new[:]=[b,g,r]\n",
    "\n",
    "cv2.imshow(\"gf\",new)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ce299e-74b3-47f0-91ce-a358c620558f",
   "metadata": {},
   "source": [
    "getTrackbarPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b9afcf-bc1c-431d-b50d-83d94d0a8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello(x):\n",
    "    pass\n",
    "\n",
    "\n",
    "new = np.zeros((500,500,3),np.uint8)*255\n",
    "cv2.namedWindow(\"colour\")\n",
    "\n",
    "cv2.createTrackbar(\"on\",\"colour\",0,100,hello)\n",
    "\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"colour\",new)\n",
    "    if cv2.waitKey(1) & 0xff == ord(\"p\"):\n",
    "        break\n",
    "    on=cv2.getTrackbarPos(\"on\",\"colour\")\n",
    "    new[:]=[on,0,0]\n",
    "\n",
    "cv2.imshow(\"gf\",new)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2196966f-6ac6-47e0-9940-97f7e6fd41a8",
   "metadata": {},
   "source": [
    "region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "620c6a1b-94b5-4028-a1f3-0141bbaced7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"project_image/four.jpg\")\n",
    "#img = cv2.resize(img,(00,500))\n",
    "crop = img[335:190,434:187]\n",
    "img[335:190,434:187]\n",
    "cv2.imwrite(\"save.jpg\",img)\n",
    "cv2.imshow(\"hmm\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b960cf6-011b-4016-9a01-becde021ea8c",
   "metadata": {},
   "source": [
    "flip,rotate and transpose \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a974bec1-9f6d-4db9-bb53-0ebd878cd267",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"project_image/four.jpg\")\n",
    "img = cv2.resize(img,(600,500))\n",
    "\n",
    "#flip=cv2.flip(img,2)#y axis\n",
    "#flip=cv2.flip(img,0) #x axis\n",
    "\n",
    "#rotate=cv2.rotate(img,cv2.ROTATE_180)\n",
    "#rotate=cv2.rotate(img,cv2.ROTATE_90_CLOCKWISE)\n",
    "#rotate=cv2.rotate(img,cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "transpose=cv2.transpose(img)\n",
    "\n",
    "cv2.imshow(\"hmm\",transpose)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4c1afe-e308-4cae-9d0f-04807693c62d",
   "metadata": {},
   "source": [
    "saving a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "450a5464-9fa8-485b-94a1-7bd75e9e341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    r,frame=cap.read()\n",
    "    if r==True:\n",
    "        frame=cv2.flip(frame,1)\n",
    "        cv2.imshow(\"hello\",frame)\n",
    "        if cv2.waitKey(25) & 0xff==ord(\"p\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f92123e5-11e4-48a2-9842-1312b993198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "f=cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "out=cv2.VideoWriter(\"demo.mp4\",f,30.0,(640,480),0)#30 represent frame per second\n",
    "while True:\n",
    "    r,frame=cap.read()\n",
    "    if r==True:\n",
    "        frame=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        frame=cv2.flip(frame,1)\n",
    "        out.write(frame)\n",
    "        cv2.imshow(\"he\",frame)\n",
    "        if cv2.waitKey(25) & 0xff==ord(\"p\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcae43b-5cea-42ce-aade-f9de7232c32a",
   "metadata": {},
   "source": [
    "color space\n",
    "\n",
    "\n",
    "Color spaces are a way to represent the color channels present in the image\n",
    "that gives the image that particular hue.\n",
    "RGB (Red, Green, Blue)\n",
    "CMYK (Cyan, Magenta, Yellow, Black)\n",
    "HSV (Hue, Saturation, Value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf0682e-7d51-418c-afca-786219789860",
   "metadata": {},
   "source": [
    "filter color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ff327-b3da-44fc-b681-544f5720f465",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59340279-7afd-4834-aa9e-f38c97ad5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "def hello(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"demo\")\n",
    "\n",
    "# HSV Trackbars\n",
    "cv2.createTrackbar(\"lh\",\"demo\",0,255,hello)\n",
    "cv2.createTrackbar(\"ls\",\"demo\",0,255,hello)\n",
    "cv2.createTrackbar(\"lv\",\"demo\",0,255,hello)\n",
    "\n",
    "cv2.createTrackbar(\"uh\",\"demo\",255,255,hello)\n",
    "cv2.createTrackbar(\"us\",\"demo\",255,255,hello)\n",
    "cv2.createTrackbar(\"uv\",\"demo\",255,255,hello)\n",
    "\n",
    "while cap.isOpened():\n",
    "    r,frame=cap.read()\n",
    "    if  r==True:\n",
    "        img=cv2.resize(frame,(400,300))\n",
    "        hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "    \n",
    "        lh = cv2.getTrackbarPos(\"lh\",\"demo\")\n",
    "        ls = cv2.getTrackbarPos(\"ls\",\"demo\")\n",
    "        lv = cv2.getTrackbarPos(\"lv\",\"demo\")\n",
    "    \n",
    "        uh = cv2.getTrackbarPos(\"uh\",\"demo\")\n",
    "        us = cv2.getTrackbarPos(\"us\",\"demo\")\n",
    "        uv = cv2.getTrackbarPos(\"uv\",\"demo\")\n",
    "    \n",
    "        lower = np.array([lh, ls, lv])\n",
    "        upper = np.array([uh, us, uv])\n",
    "    \n",
    "        mask = cv2.inRange(hsv_img, lower, upper)\n",
    "        res = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "        cv2.imshow(\"Original\", img)\n",
    "        cv2.imshow(\"HSV\", hsv_img)\n",
    "        cv2.imshow(\"Mask\", mask)\n",
    "        cv2.imshow(\"Result\", res)\n",
    "    \n",
    "        if cv2.waitKey(1) & 0xFF == ord('p'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f29522-dff7-4571-aaad-89187cddd91e",
   "metadata": {},
   "source": [
    "perspective transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab4768c3-28c9-4e4a-b53c-9a053f9b73b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"project_image/three.jpg\")\n",
    "img=cv2.resize(img,(500,700))\n",
    "w,h=(500,700)\n",
    "\n",
    "src1=np.float32([[400,283],[2335,283],[280,183],[521,177]])\n",
    "dis=np.float32([[0,0],[w,0],[0,h],[w,h]])\n",
    "mask=cv2.getPerspectiveTransform(src1,dis)\n",
    "\n",
    "new=cv2.warpPerspective(img,mask,(w,h))\n",
    "\n",
    "cv2.imshow(\"ji\",img)\n",
    "cv2.imshow(\"hi\",new)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "052c6148-5d82-46bb-b4a4-bcbd60131b8f",
   "metadata": {},
   "source": [
    "simple threshold\n",
    "\n",
    "->Thresholding is one of the most common (and basic) segmentation techniques\n",
    "  in computer vision and it allows us to separate the foreground (i.e., the objects\n",
    "  that we are interested in) from the background of the image.\n",
    "\n",
    "->Thresholding is the binarization of an image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446f6884-d6ce-4f2f-8c53-7f0ae716d0e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d652c8e-bf0e-47f1-9c92-21e89795987d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59699b03-e7a6-424b-bc9b-2a9a5817ded4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
